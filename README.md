# Crisp‑Core

**Goal:** real‑time speech inference (< 250 ms P95) delivered as a micro‑service built with **Whisper.cpp**, **Qdrant**, and **OpenTelemetry**.

> Why?  To showcase end‑to‑end AI‑infra skills—model serving, vector search, observability, and cost/latency trade‑offs.

## Roadmap
- [ ] CPU baseline (whisper.cpp)
- [ ] Vector search via Qdrant
- [ ] OTEL instrumentation
- [ ] GPU path + cost model
